{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ravigv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.matutils import softcossim\n",
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix\n",
    "from gensim.models import FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravigv\n",
      "C:\\Users\\ravigv\\Documents\\cosine_sim\n",
      "Wall time: 965 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Setting path \n",
    "# Get working directory\n",
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "# Set working directory\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\ravigv\\\\Documents\\\\cosine_sim\\\\') \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"apple apple is fruit\"\n",
    "doc = \"apple is phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  70.71 %\n",
      "Wall time: 30.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2928932188134524"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cosine similarity countvectorizer - BOW model\n",
    "\n",
    "def cosine_distance_countvectorizer_method(s1, s2):\n",
    "    \n",
    "    # sentences to list\n",
    "    allsentences = [s1 , s2]\n",
    "    \n",
    "    # packages\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from scipy.spatial import distance\n",
    "    \n",
    "    # text to vector\n",
    "    vectorizer = CountVectorizer()\n",
    "    all_sentences_to_vector = vectorizer.fit_transform(allsentences)\n",
    "    text_to_vector_v1 = all_sentences_to_vector.toarray()[0].tolist()\n",
    "    text_to_vector_v2 = all_sentences_to_vector.toarray()[1].tolist()\n",
    "    \n",
    "    # distance of similarity\n",
    "    cosine = distance.cosine(text_to_vector_v1, text_to_vector_v2)\n",
    "    print('Similarity of two sentences are equal to ',round((1-cosine)*100,2),'%')\n",
    "    return cosine\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "cosine_distance_countvectorizer_method(query, doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  [0.77459667]\n",
      "Wall time: 106 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.77459667])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cosine similarity tfidfvectorizer method\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_tf_idf_query_OneDoc_similarity(docs, query):\n",
    "    docTFIDF = TfidfVectorizer().fit_transform([docs])\n",
    "    queryTFIDF = TfidfVectorizer().fit([docs])\n",
    "    queryTFIDF = queryTFIDF.transform([query])\n",
    "\n",
    "    cosineSimilarities = cosine_similarity(queryTFIDF, docTFIDF).flatten()\n",
    "    print('Similarity of two sentences are equal to ',cosineSimilarities)\n",
    "    return cosineSimilarities\n",
    "\n",
    "get_tf_idf_query_OneDoc_similarity(doc, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  [0.81649658]\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81649658])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#  linear kernel cosine similarity tfidfvectorizer method\n",
    "\n",
    "def lk_cosim_tfidfvectorizer_method2(docs, query):\n",
    "    docTFIDF = TfidfVectorizer().fit_transform([docs])\n",
    "    queryTFIDF = TfidfVectorizer().fit([docs])\n",
    "    queryTFIDF = queryTFIDF.transform([query])\n",
    "\n",
    "    lk_cosim = linear_kernel(queryTFIDF, docTFIDF).flatten()\n",
    "    print('Similarity of two sentences are equal to ',lk_cosim)\n",
    "    return lk_cosim\n",
    "\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "lk_cosim_tfidfvectorizer_method2(doc, query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  0.8865374078515251\n",
      "Wall time: 4.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8865374078515251"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cosine similarity using spacy small model\n",
    "\n",
    "def spacy_cosim(query, doc):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc1 = nlp(query)\n",
    "    doc2 = nlp(doc)\n",
    "    sp_cosim = doc1.similarity(doc2)\n",
    "    print('Similarity of two sentences are equal to ',sp_cosim)\n",
    "    return sp_cosim\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "spacy_cosim(query, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  0.7795348503474273\n",
      "Wall time: 5.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7795348503474273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Cosine similarity using spacy medium model\n",
    "import spacy\n",
    "\n",
    "def spacy_cosim(query, doc):\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    doc1 = nlp(query)\n",
    "    doc2 = nlp(doc)\n",
    "    sp_cosim = doc1.similarity(doc2)\n",
    "    print('Similarity of two sentences are equal to ',sp_cosim)\n",
    "    return sp_cosim\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "spacy_cosim(query, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of two sentences are equal to  0.7795348503474273\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7795348503474273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Spacy cosine similarity with large model \n",
    "def spacy_cosim(query, doc):\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    doc1 = nlp(query)\n",
    "    doc2 = nlp(doc)\n",
    "    sp_cosim = doc1.similarity(doc2)\n",
    "    print('Similarity of two sentences are equal to ',sp_cosim)\n",
    "    return sp_cosim\n",
    "\n",
    "\n",
    "# Calling the function\n",
    "spacy_cosim(query, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146543\n",
      "Wall time: 5min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7146543"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# SoftCosine similarity gensim fasttext model\n",
    "\n",
    "def gensim_cosim(query, doc):\n",
    "    \n",
    "    query1 = query.split()\n",
    "    doc1 = doc.split()\n",
    "    \n",
    "    # Download the FastText model\n",
    "    fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')\n",
    "    # sentences to list\n",
    "    docs = [query1, doc1]\n",
    "    # Prepare a dictionary and a corpus.\n",
    "    dictionary = corpora.Dictionary(docs)\n",
    "    # Prepare the similarity matrix\n",
    "    similarity_index = WordEmbeddingSimilarityIndex(fasttext_model300)\n",
    "    similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary)\n",
    "\n",
    "    # Convert the sentences into bag-of-words vectors.\n",
    "    bow_query = dictionary.doc2bow(query1)\n",
    "    bow_doc = dictionary.doc2bow(doc1)\n",
    "\n",
    "# Compute soft cosine similarity\n",
    "    print(similarity_matrix.inner_product(bow_query, bow_doc, normalized=True))\n",
    "    return similarity_matrix.inner_product(bow_query, bow_doc, normalized=True)\n",
    "\n",
    "    \n",
    "    \n",
    "gensim_cosim(query, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector1: Counter({'apple': 1, 'is': 1, 'fruit': 1})\n",
      "Vector2: Counter({'apple': 1, 'is': 1, 'phone': 1})\n",
      "Cosine: 0.6666666666666667\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Custom cosine similarity \n",
    "\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r\"\\w+\")\n",
    "\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "   \n",
    "    if not denominator:\n",
    "        return  0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "text1 = \"apple is fruit\"\n",
    "text2 = \"apple is phone\"\n",
    "\n",
    "vector1 = text_to_vector(text1)\n",
    "vector2 = text_to_vector(text2)\n",
    "\n",
    "cosine = get_cosine(vector1, vector2)\n",
    "\n",
    "print(\"Vector1:\", vector1)\n",
    "print(\"Vector2:\", vector2)\n",
    "print(\"Cosine:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
